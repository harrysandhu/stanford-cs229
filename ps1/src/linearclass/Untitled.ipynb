{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression as LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./ds1_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.c_[np.ones((800,1)), data[['x_1', 'x_2']]], np.array(data['y']).reshape(800,1)\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    \"\"\"Logistic regression with Newton's Method as the solver.\n",
    "\n",
    "    Example usage:\n",
    "        > clf = LogisticRegression()\n",
    "        > clf.fit(x_train, y_train)\n",
    "        > clf.predict(x_eval)\n",
    "    \"\"\"\n",
    "    def __init__(self, step_size=0.01, max_iter=1000000, eps=1e-5,\n",
    "                 theta_0=None, verbose=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            step_size: Step size for iterative solvers only.\n",
    "            max_iter: Maximum number of iterations for the solver.\n",
    "            eps: Threshold for determining convergence.\n",
    "            theta_0: Initial guess for theta. If None, use the zero vector.\n",
    "            verbose: Print loss values during training.\n",
    "        \"\"\"\n",
    "        self.theta = theta_0\n",
    "        self.step_size = step_size\n",
    "        self.max_iter = max_iter\n",
    "        self.eps = eps\n",
    "        self.verbose = verbose\n",
    "        self.m = 0  # num of training examples\n",
    "        self.n = 0 # num of features\n",
    "\n",
    "    def sigmoid(self, theta, x):\n",
    "        #hypothesis function\n",
    "        h = []\n",
    "        for xi in x:\n",
    "            xi = xi.reshape(1,3)\n",
    "            v = 1 / (1 + np.exp(-xi.dot(theta)))\n",
    "            h.append(v)\n",
    "        return np.array(h).reshape(-1, 1)\n",
    "\n",
    "    def j_prime(self, theta, x, y):\n",
    "        return (-1/self.m)*x.T.dot(y - self.sigmoid(theta, x))\n",
    "    \n",
    "\n",
    "    def j_hess(self, theta, x, y):\n",
    "        g = self.sigmoid(theta, x)\n",
    "        s = np.diag(np.diag(g.dot((1-g).T)))\n",
    "        return (1/self.m)*x.T.dot(s).dot(x)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"Run newton's method to minimize j(theta) for logistic regression.\"\"\"\n",
    "        self.m = len(x)\n",
    "        self.n = len(x[0])\n",
    "        self.theta = np.zeros((self.n,1))\n",
    "#         print(self.sigmoid(self.theta, x))\n",
    "        print(self.j_prime(self.theta, x, y))\n",
    "#         print(np.linalg.inv(self.j_hess(self.theta, x, y)).dot(self.j_prime(self.theta, x, y)))\n",
    "        count = 0\n",
    "        theta = np.linalg.inv(self.j_hess(self.theta, x, y)).dot(self.j_prime(self.theta, x, y))\n",
    "        while abs(theta - self.theta).all() > self.eps and count < self.max_iter:\n",
    "            self.theta = theta\n",
    "            hessinv = np.linalg.inv(self.j_hess(theta, x, y)).reshape(self.n, self.n)\n",
    "            print(hessinv)\n",
    "            theta = theta - hessinv.dot(self.j_prime(theta, x, y))\n",
    "            count += 1\n",
    "                \n",
    "        print(self.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.        ]\n",
      " [-0.39548487]\n",
      " [-2.5214322 ]]\n",
      "[[13.54645873 -6.58288573 -0.01400028]\n",
      " [-6.58288573  8.12865678 -0.60350622]\n",
      " [-0.01400028 -0.60350622  0.13040407]]\n",
      "[[ 53.32729473 -29.8210194   -1.48135188]\n",
      " [-29.8210194   31.7900795   -2.28742784]\n",
      " [ -1.48135188  -2.28742784   1.00292524]]\n",
      "[[17.89086609 -4.4462476  -1.79387412]\n",
      " [-4.4462476  11.32316497 -2.00701235]\n",
      " [-1.79387412 -2.00701235  1.03508051]]\n",
      "[[24.88312885 -8.51259629 -2.05829504]\n",
      " [-8.51259629 14.95347225 -2.17398646]\n",
      " [-2.05829504 -2.17398646  1.16906151]]\n",
      "[[27.30511356 -9.88487584 -2.16654554]\n",
      " [-9.88487584 16.14764084 -2.22188999]\n",
      " [-2.16654554 -2.22188999  1.21596112]]\n",
      "[[27.45478414 -9.96777446 -2.17404299]\n",
      " [-9.96777446 16.21992894 -2.22488052]\n",
      " [-2.17404299 -2.22488052  1.21910989]]\n",
      "[[27.45525912 -9.96803223 -2.17406901]\n",
      " [-9.96803223 16.22015643 -2.22489074]\n",
      " [-2.17406901 -2.22489074  1.21912083]]\n",
      "[[27.45525912 -9.96803223 -2.17406901]\n",
      " [-9.96803223 16.22015643 -2.22489074]\n",
      " [-2.17406901 -2.22489074  1.21912083]]\n",
      "[[-2.40859977]\n",
      " [ 1.03437317]\n",
      " [ 0.24480705]]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    " def sigm(theta, x):\n",
    "        #hypothesis function\n",
    "    h = []\n",
    "    for xi in x:\n",
    "        xi = xi.reshape(1,3)\n",
    "        v = 1 / (1 + np.exp(-xi.dot(theta)))\n",
    "        h.append(v)\n",
    "    return np.array(h).reshape(-1, 1)\n",
    "\n",
    "yt = sigm(clf.theta, x)\n",
    "\n",
    "for i in range(len(yt)):\n",
    "    if yt[i] <= 0.5:\n",
    "        yt[i] = 0\n",
    "    else:\n",
    "        yt[i] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[1.] [0.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n",
      "[0.] [1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "for i in range(len(y)):\n",
    "    if yt[i] != y[i]:\n",
    "        c +=1\n",
    "        print(yt[i], y[i])\n",
    "        \n",
    "        \n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
